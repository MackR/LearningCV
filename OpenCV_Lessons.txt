Programming Practice Lessons Learned:

    1 August 9th 2022 - I'm finally starting OpenCV after doing environment setup:  0hr += 3;
        1.1 Theres a configuration file that allows you to choose your compiler, include paths, debugging programs, and how the debugging is launched and run, and what is compiled
        1.2 Modifying the task.json file can change the way the debugger acts towards you and eliminate some errors with finding libraries.
        1.3 You can execute programs and give them variables by doing ./main.cpp variable1 variable2
        1.4 printf(“ blah blah”) works just like std::cout.  
        1.5  std::cout needs #include <iostream>
        1.6 The difference between #include <“library”> and #include “library” is that the brackets uses the include path, and is part of standard installed libraries, while the later looks for local files related and quite close to the program in the files folder.
        1.7 You need to configure VS Code before using it! Lots of setup.
        1.8 Make a separate bin directory for when you compile and build your executables.  Then tell the compiler to put them in that bin directory
        1.9 g++ is generally the compiler for c++ programs, while gcc is for c programs
    2 August 10th 2022: 3hr += 7 hours;
        2.1 There are space scales in computer vision that control how much resolution a computer sees an image with and help it understand how large it should be looking o interpret things
        2.2 A callback function is one that you feed to another function and it is then called from inside the function.
        2.3 The Trackbar for the video function allows you to give it a callback function that is called anytime the Trackbar is moved.  Example cv::createTrackbar(“$trackbarName”, “$desiredWindow”, &trackbarPositionVariable, videoFrameNumber/Trackbarsize, callbackFunction).  “Callback function is called every time the tracker bar is clicked
        2.4 The pytdown() function is used for downsampling every other pixel and allows videos to become half as big as they were before. 
        2.5 Canny edge detector uses convolution to find edges in programs. 
        2.6 The image processing functions have a “cache memory?” that allows them to temporarily store your variables and so you can chain image processing functions together
    3 August 11th 2022: 10hr += 6
        3.1 The cv::Point p<2i>(x,y) operator is useful for setting points
        3.2 Compare() function has multiple operators for comparing two files together and making outputting the result of their comparison. I attempted to use this for tracking motion.
        3.3 Color is often determined by a {0,0,0} vector/scalar where it is BGR
        3.4 There are many tools for drawing in OpenCV, most of which are just polygons and text.  Nothing too special here.
        3.5 Using cv::Mat mat2(mat1) just creates a pointer of mat2 to mat1. It doesn’t actually create the data separately! If you want a completely new copy, use cv::Mat mat2 = mat1.clone(); Then it creates a completely new object. 
        3.6 There are tons of datatypes for matrices, arrays, and points, lines, etc…  they tend to have special types associated which are shorthand for stuff. 
        3.7 Sparse mats are mats that don’t have values for every spot in the array.  Mat(s) are densely populated arrays that have values in them constantly.
        3.8 cv::VideoCapture variables have cap.get(cv::CAP_PROP_FRAME_WIDTH,HEIGHT, etc..) functions in them, meanwhile Mat variables have Mat.rows, Mat.cols  and other member variables
        3.9 You can have multiple variables as arguments for a C call function, argc is the count of inputs, char** argv is the inputs themselves.
        3.10 Alpha blending is where you use different pictures and combine their values to blend images together.  It has alpha, beta, and gamma values. 
        3.11 Your mouse is tracked by OpenCV and can be used to pull events and callbacks on actions
    4 August 11th, 2022: 16hr += 4
        4.1 The short Mat and Vec datatypes are great for multiplication and all manner of calculations, compatible with eachother
        4.2 std::cout is compatible with the short form mat vec datatypes
        4.3 You can access the characters from the keyboards actual values by taking their inputs as numbers through the cv::waitKey() function and doing this:
            3.1 char key = static_cast<char>(waitKey());  This gets the ascii numbers as the actual text value
            3.2 std::string.push_back(char c) is functional for building strings, along with pop_back()
        4.4 The main datatypes you can make for the matrices are (8,16,32)(U,B,S,F,D)C(1,2,3)
        4.5 Scalar is a 4 number vector that is meant to hold x,y,z and s (magnitude/scalar) values, but it is often used for colors too.
        4.6 _tp is “type” in templates, you can use them to replace any datatype in a code piece.
        4.7 use the mat.at<_tp>(x,y) to access the value of pixels in a mat array
        4.8 you can instantiate a mat by doing cv::mat::zeros(w,h, _tp);
        4.9 If you want to fix the value that an image is displaying, you cannot just recreate the variable with a blank slate, because that leaves the vector still referenced by the window that you have open and displaying the window!  you have to use the .setto() member function?
    5 August 15th, 2022: 20hr += 6
        5.1 When accessing an array using the at<_typ>() function, it is imperative that you use the right <typ> variable! I used a short instead of a byte, and was only able to set every other pixel in my mat image. 
        5.2 There are multiple different color spaces.  HSV,BGR, LCM.  They are all useful for different things and separate different components of the color spectrum from each other in different ways, allowing your computer to read correctly from images
        5.3 Segmentation faults can come from anywhere!  You see one at a certain line in your code, but it might not be from there, it might be from earlier.  Pay close attention to datatypes and size of numbers and array access.
        5.4 cv::imshow will display images of floats if they are between 0 and 1
        5.5 When using pointers.  If you instantiate a pointer, it must point to a variable location!  You cannot pass a pointer to an object and expect it to work with a blank memory space, unless it does the setting itself. 
        5.6 You should iterate through a mat variable by getting a pointer to the row, then moving to the column. This is because the rows are contiguous, but the columns are not.  So asking a program to go to the next element in the row is easy, but going to the next element in the column requires math. Can get a pointer by using const base_type* Row = cv::mat.ptr<base_mat_datatype(byte, short, int, long, etc…>(row_num)
        5.7 Learned about template<class type> templates!  Where you can create one function or class and have the compiler determine what types it needs to instantiate in order for your code to work.
        5.8 Many small learnings, and relearning.  More to come tomorrow!
    6 August 22nd, 2022: 26hr += 6
        6.1 When asking the std::cout function to interpret the uchar variables, it defaults to chars. Need to cast as (int) before outputting
        6.2 constexpr is used for telling the compiler to calculate an expression at compile time, to save computation time later
        6.3 Use the cv::split(src, colors) function to collect the different channels of color.
            6.3.1 The color variable requires format vector<cv::Mat> Colors.  The function will handle formatting colors to correct dimensions
        6.4 A mask in OpenCV is just a cv::Mat array that uses zeros and ones to tell another function which pixels to operate on.
            6.4.1 The mask should be the same dimensions as the source material that is being mutated
        6.5 To do visual odometry, using the persistence of features of the environment between frames of a video clip, and then estimating the new locations of the features allows the user to use the collective delta of the objects to estimate your path
            6.5.1 When multiple features are moving, the camera should estimate odometry by estimating it's motion as the amount of motion that would create the minimum relative motion of the surrounding features
        6.6 People use gravity to help estimate wall and floor segmentation. We know walls are vertical and floors are horizontal.  Cameras alone don't know this, making wall and floor segmentation more difficult
        6.7 Stereo vision is best for odometry estimation and spacial mapping in general
        6.8 Colors are a big mix of numbers.  Light blue is a combination of RGB, not just blue. When filtering color, you have to interpret RGB specially to know what you are filtering. Consider HSV instead and learn
        6.9 using cv::bitwise_and(img,cv::Scalar(0,0,0),img,mask); allows filtering colors you want with mask, bitwise_not allows bit inversion of image portions
        6.10 Added a .gitignore file to my repository
    7 August 23rd, 2022: 32hr += 8
        7.01 Learned to implement trackbar control
        7.02 Callback functions have userdata parameters that allow passing a void* to the object that you care about.  You then inform the computer what pointer type it is and dereference it in order to use it
        7.03 cv::subtract() and almost all functions will reformat the object to have proper dimensions. Need to make sure you are inputtting correct image formats
        7.04 using clone1 = clone2 = img.clone() will copy img's values, and set clone1 and clone 2 pointing to the same values!  Need to use separate clone() functions for each
        7.05 Use compare() for a good way to create image masking without accessing each element of cv::Mat
        7.06 split() and merge() are useful counterparts to eachother. It's not possible to modify one channel within a Mat without accessign each value.  Split, modify, then merge
        7.07 Corners are features in computer vision that are usually unique to an image and are used to identify movement. OpenCV has functions to find features for users
        7.08 cv::goodFeaturesToTrack() will find features in an image for user
        7.09 Git revert will remove files from your computer, not just revert the repository.  Use git reflog or git checkout <commit_id> to revert to before.  Git log allows finding id'S
        7.10 Sharper images lead to better unique feature identification
    8 August 24th, 2022: 40hr += 6
        8.01 Git rebase takes all the commits you've applied to your current branch and allows you to test  as if you were reapplying all of them all the way up to another commit in another branch
        8.02 If your local repository master branch is behind the remote master branch head, but you want to use only the stuff you have in your local, you can force merge of your branch over the master with git push -f origin master:master
        8.03 When files are deleted using git rm, they are only staged to be deleted.  You can view and restore them with git status, then git checkout <file_name>
        8.04 Git revert undoes all the changes of only ONE commit.  And maintains the changes you have made on later commits
        8.05 Git reset rolls back all the commits you have made up to the commit id that you give it.
        8.06 Snippets can be used to generate boilerplate code. I created an image and empty boilerplate for opencv to avoid typing everything repeatedly
        8.07 OpenCV has a random number generator (RNG) that is a non-static object that you need to instantiate in order to use its functionality.  You can use myRNG.uniform() or .gaussian(), or .fill() and fill only works for Mat arrays
        8.08 You can define a float to a function parameter by typing the number and then putting a .f notation afterward (20.f)
        8.09 The character notation for tab is \t
        8.10 A dettached head in git is where your local git folder is pointing to an earlier commit, and you can do things with the commit, but it is not an official branch. If you leave the dettached head, you will lose changes, or you can change it into a branch.
    9 August 28th, 2022: 46hr +=  8  - Today is a culmination of a Thursday's Friday's and Sunday's efforts due to obligations the former two days
        9.01 Callback functions for C++ programs pose interesting problems relating to variable passing. Casting Void pointers works, but if one needs multiple data pieces, they have to make a custom class just for passing data.  Try to find alternatives.
        9.02 OpenCV provides excellent tools for image manipulation. If you want to combine three images together side by side, you get pointers to the columns desired, and set the columns equal to the images you want to copy. OpenCV does the rest
        9.03 The difference between mouse events and flags are interesting. It provides double methods for passing data. Events only trigger on new movement/clicking, not constant signals. Events are mutually exclusive. Meanwhile, flags may all be used simulatenously
        9.04 Image format is key, if you think something is wrong, look at image format first, then the column,row configurations
        9.05 To concatenate strings, the "+" operator is very handy, but you still have to cast variables as strings.  the std::to_string() function is great for this with ints when needed. There may be better ways.
        9.06 This summarizes the most obvious lessons for past few days.  Wrapping up IO and performing mastery exercises from past 8 chapters. Moving to tough computer vision concepts within next 2 days.
    10 August 29th, 2022: 54hr += 6 - Histograms, fillConvexPoly(), addWeighted(), drawing functions
        10.01 When inputting parameters, if the function calls for a &var, this means it will auto retrieve the address of the variable and not make a new variable to work with.  Input the variable as desired in regular form
        10.02 Histograms categorize data into bins which are used for statistics.  Normalizing histograms is a good Practice
        10.03 One image processing technique is to redistribute the color lightness values in an image. People can see 700-900 greyscales.  Often images are too dark for people to see, so redistributing will make images more visible and useful, providing "Night vision"
        10.04 When dereferencing passed information from a callback function, make sure you are aware of what variable you are modifying
        10.05 After drawing something, use imshow immediately.  It will help debug if wrong, and make things work if right
        10.06 Did research on what to learn for future.  Conclusion is PCL, Deep Learning setup (Keras? & Tensorflow?), and yolo perhaps. Stereo vision is valuable and pose estimation
    11 August 30th, 2022: 60hr += 7  - Learned about warping images, erosion, dilation, sobel gradients, partial derivatives, gradient direction and magnitude and histograms
        11.01 A separable kernel is one where you can break it up into 2 or 3 pieces that you multiply by eachother to calculate a filter.  the computation time is the different between 2n and n^2. So one should always try to separate filters
        11.02 A sobel filter is a gradient filter that uses vertical or horizontal gradients.  It is generalizable in other ways. By calculating differences across kernels, you can find corners of images. This is like partial derivative in x and y directions
        11.03 white hat operation isolates areas that are brighter than their surroundings. Black hat finds areas darker than surroundings
        11.04 Dilation is where you take the maximum value found in a kernel and use it as the result of the convolution
        11.05 Erosion is where you use the minimum value of a convolution and use it as the result
        11.06 Opening and closing operations are combinations of the above two operations in different orders
        11.07 There are multiple smoothing functions that all have similar results and perform in similar ways:
            01. blur() is just an averaging over the kernel
            02. medianBlur() is taking the median value over the kernel during convolution.  Good for noisy images
            03. gaussianBlur() is a weighted kernel according to sigma values in x and y directions with different weights for each pixel in the kernel.  The anchor has highest weight value
            04. bilateralFilter is different from gaussian and useful for image segmenting because although it is a weighted filter, it weights pixels in the kernel depending on their intensity similarity to the anchor's intensity. This preserves edges by encouraging only the uniform sections to smooth eachother out and not mix with other intensity sections
        11.08 Depth of output is the variable value (CV_8U, CV_16U, etc...)
        11.09 In opencv, a kernel is called a structuring element. To make my own kernel I can use cv::getStructuringElement()
        11.10 Use cv::filter2D() to filter using your own kernels.  OpenCV is optimized for this, DON'T DO IT MANUALLY
        11.11 Histograms are useful for categorizing data from images. This statistical interpretation can be useful for image identification. Histograms can function in multiple dimensions. Need more learning here
        11.12 You can warp an image by using warp matricies. This is like in mechanical engineering where we would rotate coordinate frames by multiplying by the correct rotation matrix.  This can be done by multiplying over an entire matrix to scale, rotate, skew and perform many other operations
        11.13 Histograms should be normalized in order to work with their data.  It makes it all easier. 
        11.14 Arrow keys have no assigned ascii values and are simply interpretted by a program in windows.  This explained why online video games always use WASD
        11.15 cv::warpAffine() can do the warping with simple 2x2 matrices.  But to do more complex "perspective" warping, one needs a 3x3 matrix
    12 September 19th 2022: 67hr += 4 - Reviewed dilation, erosion, opening, and closing, along with other image operations. Completed exercises 1-4 of Chapter 10
        12.01 Resize does not add padding to the boundaries of the images, it actually resizes everything inside
        12.02 Abs diff subtracting two barely shifted images creates an outline of every object/major boundary in the image. Incredibly interesting
        12.03 Subtracting two images shows difference between two images. I've begun making a "difference finding program" that will spot the differences in two images and circle them. This encompassed most of the day's work.
        12.04 Shifting two slightly skewed images to realign them is not super easy, it requires summing of the entire image and checking minimums
            12.04.01 Operation is similar to convolution. Could you use a convolution to complete? What about a convolution between two images?
        12.05 Morphological gradients use dilation and erosion to clean up images and then highlight an objects outline. This is good because it does it over the whole image and on parts a sobel filter might miss.
    13 September 20th 2022: 71hr += 8 - Continued work on the spot the difference program. Could improve it by adding ROI box to main differences. Learned Viola-Jones face detect algorithm concepts
        13.01 It is extremely important that you format whatever data you get when you first start a program. Once the data is formatted, issues won't cascade.
        13.02 You can pad an image by making a larger one and copying the data from the original into it. This allows you to shift the second image around ontop of the first one for alignment
        13.03 Resizing an image is a possible way to evaluate results over a large image. It provides noisy feedback but has some merit
        13.04 Another great way to get feedback is to evaluate what you want on a small part of the image, and once you get your result, apply your steps to the entire image only once
        13.05 Calculating integral images is a way to take an N^2 operation and make it 0(N). Integral images are used for summing/scanning large images for their features. Need to Practice more
        13.06 It is incredibly useful to visualize each step along the way to your result. Do small checks of each image processing steps along the way using imshow and waitKey(0). Much better than std::cout
        13.07 Thresholding is a great way to remove noise from a system. the closing() process isn't as good for cleaning up if the difference between noise and signal isn't strong
        13.08 Using a small mat variable of a large image is a great way to examine small portions of an image for calculation, and it provides it's own padding along the edges
        13.09 Use constants more often!
        13.10 Using the function morphologicalEx() I can access the blackhat, whitehat, opening, and closing methods, and more. Opening seems to clean up the image better than doing the individual operations themselves.
        13.11 Opening method appears to be really good at identifying whole objects with color changes, but small lines will be lost in the process.
    14 October 3rd, 2022: 79hr += 8 - 
        14.01 Smoothing functions don't have masks naturally, but you can make your own mask by separating the masked region into its own image, then blurring that portion, then masked addition/assignment back into the original photo, and it will achieve the same effect
        14.02 Flood fill function is great for comparing connected regions of a mask or even natively in an image. It will retrieve area for you and you can use it to remove "noise" objects from an image. Or to filter for certain size objects. VERY useful
        14.03 HSV representation is good for picking out blue regions of a picture, or any specific color region you are looking for. Threshold functions are important for masks
        14.04 Can use bitwise functions with masks to expand or filter their regions. I used it for combining a saturation strength filter with the blue hue to find regions that were more blue than other regions 
        14.05 Top hat function has some usefulness in finding corners of a room, but only if lighting gradients are strong.  Still need to learn pointcloud for better sensing
        14.06 Super important to order the row and col settings right, it easily breaks a program, and opencv isn't consistent
        14.07 It might be possible to create adaptive filters for specific color types
        14.08 Imshow does not accept HSV images, they must be converted back to orignal BGR
        14.09 Almost done with chapter 10 exercises and lessons. There are 18 exercises!
    15 October 4th, 2022: 87hr += 6 - 
        15.01 There is something wrong about the add function where if you try to add a mask and unmasked image together
        15.02 Canny edge detection is probably best for detecting solid edges, but, Laplacian is very strong too, and finds edges while bringing in speckled noise that can be filtered with special methods
        15.03 Image and mask naming is super important for readability of code.  Structured and labelled steps in the programming process are also super important
        15.04 Using the two different partial derivatives of the sobel filter might be good, and then combining them together for edge detection, but it needs some work.
        15.05 Set to function has a masking feature, which is incredibly useful img.setTo(0, mask) makes everything in the mask 0!
        15.06 Fewer hard set lessons learned yesterday, but more general learning about how to code, structure, what algorithms to use, and how to make good outputs
        15.07 Developed my own first use for typedef keyword by creating a scanning snippet that goes through an image pixel by pixel, using the PIXEL as the special type which could be any size depending on the image!
    16 October 5th, 2022: 93hr += 6 - Day of going back to the basics and practicing inheritance, classes, header & implementation files, vectors, maps, and ENUMs. No changes within OpenCV. 
        16.01 Practiced classes and inheritance along with structs and default constructors
        16.02 Vector, map, and ENUM practice, brushing up on skills
        16.03 Reminder of header files and implementation files setup. 
        16.04 Learning lessons of how to work with math and remind myself to think about edge cases and how they clash with normal use cases.
    17 October 6th, 2022: 99hr +=  6 - Getting back to OpenCV! Hitting the 100hr mark! TIL pyrMeanShiftSegmentation and how segmentation works within feature-spaces in general
        17.01 Learned pyrMeanShiftSegmentation and how they use feature space density functions to segment colors. 
            The issue with this is if you pick too broad of a density function, or too narrow, you cannot converge on a maxima or mode
            The parameters of this function are very sensitive. The pyr feature decides how much the image is shrunk before calculation
        17.02 Feature spaces are useful for classification of objects and can be used with infinite numbers of features.  I believe they are used in machine learning
        17.03 I learned how to make my own kernel, you can do this with the command:
            cv::Mat1f k = (cv::Mat1f(5,5)<< 0,0,0,0,0,0... ) where you input all the kernel weights
        17.04 Kernels are best created by using zero sum kernel weights in order for the pictures to not become too bright.
        17.05 Often, if the weights are less than 0 total, the image will be black after filtering
        17.06 Use filter2D() in order to input your own kernel and filter an image
        17.07 To make a 45 degree line filter, you often have to put the weights in the kernel orthogonal to the line direction that you want, so that the filter will find big differences along the edges.
    18 October 7th 2022: 105hr += 5 Today I learned about the Laplacian operator and how it can kinda be used to pick out eyes in image
        18.01 The laplacian operator can be used to pick out eyes (sorta) in images. The book says it prefers a bright region in center and dark areas around, HOWEVER, after interpretting the laplacian filter myself, it appears to like dark centers and bright surroundings
        18.02 I can adjust the laplacian kernel size and it changes detection. Big kernel == big lines at edjes. Small kernel = small edge details.  The closing operation may prove useful in removing noise for laplacian
        18.03 Should consider pyrDown the image before applying laplacian in order to find pupils.  But need some way of scaling back up and translating small image coordinates to large image
        18.04 Maybe I can make my own laplacian kernel that is bigger and spread out to make it work on larger images?
        18.05 Histogram equalization is how you take an image that was captured with poor sensor range, and you spread out the inputs to the full range of the display resource, allowing the image to look better, and compensate for poor capture quality (darks are darker, whites are whiter)
            18.05.01 - equalizeHist() does this quite well
        18.06 Chapter covers resize(), but also affine and perspective transfomations. Affine transformations are simple and often maintain the image's integrity by only warping it in parallelogram ways
        18.07 Chapter also covered inpainting, but no exercises completed yet.
    19 November 1st, 2022: 110hr += 4hr  - First day back from trip doing OpenCV work. Learned to use log polar transformation function and histogram equalization in E2 and E7. Chpt 12 E2 is Hough line setup and circles
        19.01 - Wrote a mouse controlled program to manipulate an image and where the log polar transformation is performed - Chpt11 E2
        19.02 - Histogram equalization on an MRI image using simple function
        19.03 - The hough line finder and circle use the feature space representation of their parameters to find repeated locations of a line and find them in an image
            19.03.01 - Feature space is incredibly interesting. Representing a point as a locus for potential line in a space
        19.04 - Learned about fourier transform in an image, and how it's used to remove high frequency noise from image
        19.05 - Fourier transform finds the different frequency components of an image and changes it's representation to frequency space. You can represent any image as a decomposition of frequencies.
    20 November 2nd, 2022: 114hr += 6hr - Applied grabcut algorithm by making mouse controlled region that picks out section of image, removes background, inpaints the foreground and displays equalizedHist image
        20.01 - Grabcut is an algorithm that estimates foreground and background of an image and creates numbered mask of them
        20.02 - Inpainting applied on images of people to try and remove them from images. People are too big, even on easy images. Easy algorithm through
        20.03 - Used equalizeHist to see the mask the grabCut created. Their original brightness values were 1,2,3 (invisible), equalizeHist revealed them and scales the numbers up
        20.04 - Histograms are statistical tools to interpret the summmation of data over an image. Backproject is good for histogram matching parts of images
        20.05 - Backproject best as HSV values. The OpenCV does a lot of histogram work for the user. Not too complicated. 
    21 November 4th, 2022: 120hr += 6 - Learned how to work with histograms and evaluate image similarity based on simple comparison methods
        21.01 - matchTemplate() takes a small piece of an image that you want to find within a big image and it slides it over the image, doing section comparisons with the squared error. Then returns a 2D histogram showing match strenght over the image
        21.02 - Use minMaxLoc() to find the greatest histogram bin value. 
        21.03 - compareHist() compares two histograms together by comparing the number of values lumped into each bin. Rough calculation ability. 
        21.04 - Important to normalize histogram data before using it for further calculations. Similar to ML training and test data
        21.05 - When bin width gets larger for these histogram comparisons, the "similarity" between histograms increases a lot. But this is because it's hard to be different when you only have 2 categories to choose from
        21.06 - EMD isn't a very good comparison. It just looks at groupings of colors and says if images are the same based on color
        21.07 - Learned about Signatures for EMD calculation. It just wants the histogram listed as (Value, col, row, (z,...etc)) in each row
        21.08 - Started work on backProjection given a histogram calc of flesh colored images. Not finished yet, something not working
    22 November 4th, 2022: 126hr += 12hr - Worked on the backProjection project, successfully got it working!
        22.01 - When doing backprojection, you need to take a small color sample, and then get the program to match that to other regions. Can't take a large varying color sample
        22.02 - Normalization has many methods. Linear, L1, L2, and more. Need to research their effects more, have basic understanding
        22.03 - The sobel operators give information to OpenCV about direction, +/- X and Y directions
        22.04 - Phase is useful with sobel X and Y derivatives. Magnitude as well. 
        22.05 - Reminder: You can invert a mask using cv::bitwise_not(mask, invertedMask); Useful!
        22.06 - Before finding edges, do the edge filter on the whole image, then mask the parts you want
        22.07 - Large kernel gaussian filter goes a really long way to remove noise before sobel operations
        22.08 - OpenCV calculates phase angle for sobel going from dark region to light region as clockwise from the x axis.
        22.09 - Use the mat.convertTo(type, scale*multiplier) function to make your images into any format. 
            Beware of the range of the values!
        22.10 - HSV for 32F images: H is from 0-360, NOT 0-180 like in CV_8U images. 
            32F - {0-360, 0-1, 0-1} - I think. CV_8U - {0-180, 0-255, 0-255};
        22.11 - Merge function requires a vector of arrays preassembled for it to work
        22.12 - backProject works well in the right lighting conditions, beware general use through
        22.13 - Use morphologicalEx(CLOSING) for small noise, but big noise might need floodfill iteration or connectedComponents() and zero anything below certain size.
        22.14 - BGR is unsuccessful with backprojection. Probably because hue does such a good job encapsulating the meaning of color in one number. Easy for programs.
        22.15 - findContours() is a great function that gives you vectors of contours which are vectors of points.  Tells you biggest contour and smaller ones.
        22.16 - I should start designing user friendly functions for easy application of various algorithms to see effectiveness
        22.17 - Threshold very useful for eliminating invisible noise
        22.18 - cv::VideoCapture cap;  cap.open(0) is successful with my video camera 
    23: November 6th, 2022 138hr += 6 - Built custom functions for image processing to make my work faster and easier to read. Tools can be found in CustomTools.cpp. Learned about many new C++ concepts, listed below.
        23.01 - Function pointers: A function name itself is just a pointer, and sometimes these are useful. Example below:
            23.01.1 - Desired function to point to: int Foo(int name) {}
            23.01.2 - Pointer to above function int (*fooPtr)(int); // The pointer to a function of type Foo
            23.01.3 - fooPtr = &Foo;  // assigning the address of function Foo to fooPtr
            23.01.4 - Then I can use the ptr function like this: fooPtr(5) and it will call correctly.
        23.02 - Array pointer decay: An array name is just the pointer to the first object in its array.
            23.02.01 - Caveat: Before the pointer is passed to a function, the array name contains the type of the array and can describe how big it is. Once it is passed to a function, it becomes a basic pointer
        23.03 - Keyword EXTERN has many uses. One of them is to tell the linker that a variable has been declared elsewhere already and that it should go find the variable
            Example: file a.cpp: int i = 43;  file b.cpp: extern int i; // In file b, it knows to look elsewhere for variable
        23.04 - The static keyword when used with global variables causes the variable to have internal linkage, meaning it is only seen within the local file or "translation unit" as they call it
        23.05 - The preprocessor is a feature that looks through a program before compiling it and performs certain actions called "directives". This is also used to decide what to compile in programs
            Example: I used this - #define DISPLAYIMAGE displayImages(img, #img) - because I have an overloaded function called displayImages that displays one or many images
        23.06 - I discovered it is impossible to know the name of the function or variable you have in your program just by looking at it's pointer/address. As expected. C++ doesn't have this type of introspection
        23.07 - Macros cannot be overloaded. 
        23.08 - Using sizeof(array)/sizeof(array[0]) doesn't work after the array is passed to function because of array to pointer decay
        23.09 - std::function can be used more easily for function pointers, although I haven't tried it yet.
    24: November 7th, 2022 - 144hr += 8hr - Still working on gesture recognition. calcBackProject() seems to behave differently than I initially expected. Going to learn more tomorrow
        24.01 - calcBackProject works really well at pulling out the most confident regions
                of color. Less confident regions often have more holes or black spots
                in them, and so the opening() operation is really effective at weeding these out.
                Because unconfident regions will expand the black spots, erasing the less confident areas.
                If it doesn't get rid of them completely, it at least disconnects them. Next, threshold
                bring the values to 0 or 255 depending on your desired confidence level. Finally, 
                the floodfillLargestArea() custom function comes in and grabs the best chunk of image for 
                use as an outline.
        24.02 - pyrMeanShift didn't seem to work to well in segmenting out the image for use in back backProjection
                Possibly, I need to use the pyr down parameter more to help clump things together more thoroughly.
                The program does suggest using it in some way with backprojection.
        24.03 - Gaussian blur prior to doing a sobel operator tends to thicken transition lines, making 
                Sobel operations less clean. It's quite annoying.
        24.04 - When taking sobels of backprojections, they must be filled in objects. If they are just contours, 
                or just thin lines,  they will take the angle of the inside edge and outside edge,
                which is obviously going to sum to 0 since they are opposite sides of a line.
                Therefore, when taking angles of outline of an object, make sure object is filled in. Somehow
        24.05 - Sometimes it's really useful to only look at a single channel with backprojection, but
                often more channels are better. My arm is picked out perfectly with some images where 
                the background colors don't match at all.  But some images have similar colors, and so 
                lighting differences must be used to distinguish foreground and background objects.
        24.06 - floodfillLargestArea() has secondary use of selecting the longest continuous contour in image
        24.07 - cv::Mat is pretty adaptable, however, having a calcBackProject use a single cv::Mat() 
                for input and output at the same time isn't okay because they are different types?  
                    - Need to try with other functions to confirm. 
        24.08 - Working with lots of images becomes hard quickly. Uniform naming system and arrays are desireable. 
        24.09 - The for (auto img: images) {} modern c++ feature actually pulls an instance of the image
                but I don't know if it's a copy of the image or the actual image through reference.
    25: November 8th, 2022 - 152hr += 8  - Programming went really good today! I learned about drawing contours and many more concepts of C++ listed below
        25.01 - Using Hu moments are crucial for detecting shapes and matching them up in a scale and 
                translation invariant way. Once you have the contour of an object, the moments 
                describe a lot about it in a simple way with 5-7 numbers. cv::moments() is the OpenCV
                function to perform the calculations, and is assisted by other functions.
        25.02 - Moments can be calculated as full filled in shapes or contours. They can even be weighted
                based on coloring/brightness, although OpenCV hasn't reavealed full functionality for
                that yet. Imagine an object is brighter on one end, you could use that in hu moments 
                to identify the object numerically. It might be computationally intensive thoroughly
        25.03 - If you want to determine if a point is within a polygon of any shape, you can trace a 
                ray coming out of it and if the ray goes through an odd number of polygon sides, it is
                inside the polygon. If it passes through an even number of polygon sides, it is outside it.
        25.04 - You can draw contours of a binary image with cv::findContours() and then drawContours()
        25.05 - Bounding rect will calculate a bounding rectangle around a contour. 
        25.06 - After learning about the median function, and bounding rectangles, it is incredibly easy to 
                make a car tracking bouding box drawing program assuming the camera is static and we are
                looking at a road with moving cars. I'm almost shocked that companies offer this program 
                as a service. It's so simple. The only complex part is assigning an ID to the car and 
                maintaining the ID throughout the video. But if we take a centroid and compare to centroids
                in the next video frame, the cars shouldn't have moved too much and should be able to 
                assign the centroid to the closest centroid of the next frame. Wow.
        25.07 - cv::connectedComponentsWithStats() outputs a label map where every pixel in the image
                is a number depending on what contour they belong too. The input image should be binary
        25.08 - C++, reviewed virtual keyword and learned that virtual should be applied to base class
                methods.  It basically says that eventhough the base class has its owm method, it should
                make sure that its children aren't trying to call their own method with a base class
                pointer.  Virtual tells the compiler to make sure it is using the right method. Simple enough
        25.09 - Pure virtual functions:  These take the form of Base(type1 param1, type2 param2) = 0.
                This forces all classes that inherit from base to have their own constructor of the same
                format.  Having a single pure virtual function makes a base class an abstract class. 
                Probably because no object is allowed to purely be that class anymore. 
        25.10 - When using the for(auto obj: array){}, C++ takes a COPY of the object from the array.
                If we want to work with the actual object itself. We have to do:
                for (auto& obj: array){}  . This passes by reference. 
        25.11 - Whenever we call a base class, its constructor for the base class is called, and then 
                the derived class constructor is called. This can be modified a little though. I'm
                guessing with pure virtual constructors. 
        25.12 - The #pragma directive has many uses. It is a signal to the compiler to perform certain tasks
                when compiling. The most useful for me is #pragma once. Which says to only compile a 
                file once, no matter how many times it is included by the programmer. 
                Other pragmas include #pragma startup, exit, warn, and GCC poison function()
        25.13 - Multithreading: std::thread makes it easy to make a program with multiple threads.
                If you have two functions, you can run them both simultaneously by doing:
                std::thread worker1(function, param1, ...); std::thread worker2(function2, param1, ...);
                Still need to learn a lot more about threading.
        25.14 - Reinterpret_cast<datatype> is a tricky feature that allows you to reinterpret a pointer
                to let it know that it is looking at a different type than it was before. You should 
                always reinterpret_cast to the type that the pointer is actually lookign at. 
        25.15 - LASTLY: I watched a video on background extraction that featured a busy highway/street.
                It showed how if you took the median pixel value over the course of 30 frames in a video, 
                that you could extract the background of a street incredibly easily. It was astounding. 
                OpenCV is starting to feel easier to understand, and image processing in general. Goodnight
    26: November 9th, 2022: 160hr += 10hr - Spent a lot of time working on the gesture recognition function today. Figuring out how to extract background pieces
        26.01 - After getting the gesture recognizer pulling out my arm outline. It revealed that
                if the camera is too blurry or is moving, the algorithms used for objects can be
                fragile to motion. Canny changes its lines often and may lose ability. Need to 
                work with and research algorithms that are not suceptible to motion. Or get better camera
        26.02 - Listed out all the methods possible for extracting an object from foreground
                BackProjection, grabcut, thresholding, HSV thesholding and filtering, canny edge
                background subtraction (not attempted yet), sobel filter, bilateral filtering
                and then canny edge. I've learned quite a few ways
        26.03 - Learned to calculate moments of an object and how they are rotation invariant 
                and scale invariant. Useful if your object is completely in picture and not 
                changing shape in any way. Bottles, spheres, or boxes are good, but not more 
                complex objects. 
        26.04 - Aruco codes are also really good for being read from a distance. You can perform
                transformations on them based on known dimensions and read their inputs. You can
                even put AR projections on top of the images to make it look like there is art
                or some other object there.
        26.05 - Adaptive thresholding is a good tool when lighting is changing the way your object 
                looks over a wide distance.
        26.06 - Blur filtering is incredibly important for an image to be processed. It cares 
                more about the chunks of color than the tiny details within the chunks of color.
                Median filter has promise, bilateral is really good, but slow. Same for pyrMeanShift.
        26.07 - Need to learn more about HSV thresholding and its uses. 
        26.08 - Backprojection has a lot more promise than I originally thought. It could identify
                uniform backgrounds and possibly deal with motion very well. 
        26.09 - Canny is really good with a ratio of 15:1. It removes most small detail and leaves
                the main outline of larger objects. 
        26.10 - Started working with Boost library today and discovered the circular buffer datatype.
                Looking forward to learning more about hwo to use it since boost is important, and
                in this case fits my needs perfectly. 
        26.11 - Just like we need filtering on the images, out results from the images need filtering 
                too. My gesture recognition oscillated back and forth between different matches,
                but the mode of the matches seemed to fit correctly.
        
