Programming Practice Lessons Learned:

    1 August 9th 2022 - I'm finally starting OpenCV after doing environment setup:  0hr += 3;
        1.1 Theres a configuration file that allows you to choose your compiler, include paths, debugging programs, and how the debugging is launched and run, and what is compiled
        1.2 Modifying the task.json file can change the way the debugger acts towards you and eliminate some errors with finding libraries.
        1.3 You can execute programs and give them variables by doing ./main.cpp variable1 variable2
        1.4 printf(“ blah blah”) works just like std::cout.  
        1.5  std::cout needs #include <iostream>
        1.6 The difference between #include <“library”> and #include “library” is that the brackets uses the include path, and is part of standard installed libraries, while the later looks for local files related and quite close to the program in the files folder.
        1.7 You need to configure VS Code before using it! Lots of setup.
        1.8 Make a separate bin directory for when you compile and build your executables.  Then tell the compiler to put them in that bin directory
        1.9 g++ is generally the compiler for c++ programs, while gcc is for c programs
    2 August 10th 2022: 3hr += 7 hours;
        2.1 There are space scales in computer vision that control how much resolution a computer sees an image with and help it understand how large it should be looking o interpret things
        2.2 A callback function is one that you feed to another function and it is then called from inside the function.
        2.3 The Trackbar for the video function allows you to give it a callback function that is called anytime the Trackbar is moved.  Example cv::createTrackbar(“$trackbarName”, “$desiredWindow”, &trackbarPositionVariable, videoFrameNumber/Trackbarsize, callbackFunction).  “Callback function is called every time the tracker bar is clicked
        2.4 The pytdown() function is used for downsampling every other pixel and allows videos to become half as big as they were before. 
        2.5 Canny edge detector uses convolution to find edges in programs. 
        2.6 The image processing functions have a “cache memory?” that allows them to temporarily store your variables and so you can chain image processing functions together
    3 August 11th 2022: 10hr += 6
        3.1 The cv::Point p<2i>(x,y) operator is useful for setting points
        3.2 Compare() function has multiple operators for comparing two files together and making outputting the result of their comparison. I attempted to use this for tracking motion.
        3.3 Color is often determined by a {0,0,0} vector/scalar where it is BGR
        3.4 There are many tools for drawing in OpenCV, most of which are just polygons and text.  Nothing too special here.
        3.5 Using cv::Mat mat2(mat1) just creates a pointer of mat2 to mat1. It doesn’t actually create the data separately! If you want a completely new copy, use cv::Mat mat2 = mat1.clone(); Then it creates a completely new object. 
        3.6 There are tons of datatypes for matrices, arrays, and points, lines, etc…  they tend to have special types associated which are shorthand for stuff. 
        3.7 Sparse mats are mats that don’t have values for every spot in the array.  Mat(s) are densely populated arrays that have values in them constantly.
        3.8 cv::VideoCapture variables have cap.get(cv::CAP_PROP_FRAME_WIDTH,HEIGHT, etc..) functions in them, meanwhile Mat variables have Mat.rows, Mat.cols  and other member variables
        3.9 You can have multiple variables as arguments for a C call function, argc is the count of inputs, char** argv is the inputs themselves.
        3.10 Alpha blending is where you use different pictures and combine their values to blend images together.  It has alpha, beta, and gamma values. 
        3.11 Your mouse is tracked by OpenCV and can be used to pull events and callbacks on actions
    4 August 11th, 2022: 16hr += 4
        4.1 The short Mat and Vec datatypes are great for multiplication and all manner of calculations, compatible with eachother
        4.2 std::cout is compatible with the short form mat vec datatypes
        4.3 You can access the characters from the keyboards actual values by taking their inputs as numbers through the cv::waitKey() function and doing this:
            3.1 char key = static_cast<char>(waitKey());  This gets the ascii numbers as the actual text value
            3.2 std::string.push_back(char c) is functional for building strings, along with pop_back()
        4.4 The main datatypes you can make for the matrices are (8,16,32)(U,B,S,F,D)C(1,2,3)
        4.5 Scalar is a 4 number vector that is meant to hold x,y,z and s (magnitude/scalar) values, but it is often used for colors too.
        4.6 _tp is “type” in templates, you can use them to replace any datatype in a code piece.
        4.7 use the mat.at<_tp>(x,y) to access the value of pixels in a mat array
        4.8 you can instantiate a mat by doing cv::mat::zeros(w,h, _tp);
        4.9 If you want to fix the value that an image is displaying, you cannot just recreate the variable with a blank slate, because that leaves the vector still referenced by the window that you have open and displaying the window!  you have to use the .setto() member function?
    5 August 15th, 2022: 20hr += 6
        5.1 When accessing an array using the at<_typ>() function, it is imperative that you use the right <typ> variable! I used a short instead of a byte, and was only able to set every other pixel in my mat image. 
        5.2 There are multiple different color spaces.  HSV,BGR, LCM.  They are all useful for different things and separate different components of the color spectrum from each other in different ways, allowing your computer to read correctly from images
        5.3 Segmentation faults can come from anywhere!  You see one at a certain line in your code, but it might not be from there, it might be from earlier.  Pay close attention to datatypes and size of numbers and array access.
        5.4 cv::imshow will display images of floats if they are between 0 and 1
        5.5 When using pointers.  If you instantiate a pointer, it must point to a variable location!  You cannot pass a pointer to an object and expect it to work with a blank memory space, unless it does the setting itself. 
        5.6 You should iterate through a mat variable by getting a pointer to the row, then moving to the column. This is because the rows are contiguous, but the columns are not.  So asking a program to go to the next element in the row is easy, but going to the next element in the column requires math. Can get a pointer by using const base_type* Row = cv::mat.ptr<base_mat_datatype(byte, short, int, long, etc…>(row_num)
        5.7 Learned about template<class type> templates!  Where you can create one function or class and have the compiler determine what types it needs to instantiate in order for your code to work.
        5.8 Many small learnings, and relearning.  More to come tomorrow!
    6 August 22nd, 2022: 26hr += 6
        6.1 When asking the std::cout function to interpret the uchar variables, it defaults to chars. Need to cast as (int) before outputting
        6.2 constexpr is used for telling the compiler to calculate an expression at compile time, to save computation time later
        6.3 Use the cv::split(src, colors) function to collect the different channels of color.
            6.3.1 The color variable requires format vector<cv::Mat> Colors.  The function will handle formatting colors to correct dimensions
        6.4 A mask in OpenCV is just a cv::Mat array that uses zeros and ones to tell another function which pixels to operate on.
            6.4.1 The mask should be the same dimensions as the source material that is being mutated
        6.5 To do visual odometry, using the persistence of features of the environment between frames of a video clip, and then estimating the new locations of the features allows the user to use the collective delta of the objects to estimate your path
            6.5.1 When multiple features are moving, the camera should estimate odometry by estimating it's motion as the amount of motion that would create the minimum relative motion of the surrounding features
        6.6 People use gravity to help estimate wall and floor segmentation. We know walls are vertical and floors are horizontal.  Cameras alone don't know this, making wall and floor segmentation more difficult
        6.7 Stereo vision is best for odometry estimation and spacial mapping in general
        6.8 Colors are a big mix of numbers.  Light blue is a combination of RGB, not just blue. When filtering color, you have to interpret RGB specially to know what you are filtering. Consider HSV instead and learn
        6.9 using cv::bitwise_and(img,cv::Scalar(0,0,0),img,mask); allows filtering colors you want with mask, bitwise_not allows bit inversion of image portions
        6.10 Added a .gitignore file to my repository
    7 August 23rd, 2022: 32hr += 8
        7.01 Learned to implement trackbar control
        7.02 Callback functions have userdata parameters that allow passing a void* to the object that you care about.  You then inform the computer what pointer type it is and dereference it in order to use it
        7.03 cv::subtract() and almost all functions will reformat the object to have proper dimensions. Need to make sure you are inputtting correct image formats
        7.04 using clone1 = clone2 = img.clone() will copy img's values, and set clone1 and clone 2 pointing to the same values!  Need to use separate clone() functions for each
        7.05 Use compare() for a good way to create image masking without accessing each element of cv::Mat
        7.06 split() and merge() are useful counterparts to eachother. It's not possible to modify one channel within a Mat without accessign each value.  Split, modify, then merge
        7.07 Corners are features in computer vision that are usually unique to an image and are used to identify movement. OpenCV has functions to find features for users
        7.08 cv::goodFeaturesToTrack() will find features in an image for user
        7.09 Git revert will remove files from your computer, not just revert the repository.  Use git reflog or git checkout <commit_id> to revert to before.  Git log allows finding id'S
        7.10 Sharper images lead to better unique feature identification
    8 August 24th, 2022: 40hr += 6
        8.01 Git rebase takes all the commits you've applied to your current branch and allows you to test  as if you were reapplying all of them all the way up to another commit in another branch
        8.02 If your local repository master branch is behind the remote master branch head, but you want to use only the stuff you have in your local, you can force merge of your branch over the master with git push -f origin master:master
        8.03 When files are deleted using git rm, they are only staged to be deleted.  You can view and restore them with git status, then git checkout <file_name>
        8.04 Git revert undoes all the changes of only ONE commit.  And maintains the changes you have made on later commits
        8.05 Git reset rolls back all the commits you have made up to the commit id that you give it.
        8.06 Snippets can be used to generate boilerplate code. I created an image and empty boilerplate for opencv to avoid typing everything repeatedly
        8.07 OpenCV has a random number generator (RNG) that is a non-static object that you need to instantiate in order to use its functionality.  You can use myRNG.uniform() or .gaussian(), or .fill() and fill only works for Mat arrays
        8.08 You can define a float to a function parameter by typing the number and then putting a .f notation afterward (20.f)
        8.09 The character notation for tab is \t
        8.10 A dettached head in git is where your local git folder is pointing to an earlier commit, and you can do things with the commit, but it is not an official branch. If you leave the dettached head, you will lose changes, or you can change it into a branch.
    9 August 28th, 2022: 46hr +=  8  - Today is a culmination of a Thursday's Friday's and Sunday's efforts due to obligations the former two days
        9.01 Callback functions for C++ programs pose interesting problems relating to variable passing. Casting Void pointers works, but if one needs multiple data pieces, they have to make a custom class just for passing data.  Try to find alternatives.
        9.02 OpenCV provides excellent tools for image manipulation. If you want to combine three images together side by side, you get pointers to the columns desired, and set the columns equal to the images you want to copy. OpenCV does the rest
        9.03 The difference between mouse events and flags are interesting. It provides double methods for passing data. Events only trigger on new movement/clicking, not constant signals. Events are mutually exclusive. Meanwhile, flags may all be used simulatenously
        9.04 Image format is key, if you think something is wrong, look at image format first, then the column,row configurations
        9.05 To concatenate strings, the "+" operator is very handy, but you still have to cast variables as strings.  the std::to_string() function is great for this with ints when needed. There may be better ways.
        9.06 This summarizes the most obvious lessons for past few days.  Wrapping up IO and performing mastery exercises from past 8 chapters. Moving to tough computer vision concepts within next 2 days.
    10 August 29th, 2022: 54hr += 6 - Histograms, fillConvexPoly(), addWeighted(), drawing functions
        10.01 When inputting parameters, if the function calls for a &var, this means it will auto retrieve the address of the variable and not make a new variable to work with.  Input the variable as desired in regular form
        10.02 Histograms categorize data into bins which are used for statistics.  Normalizing histograms is a good Practice
        10.03 One image processing technique is to redistribute the color lightness values in an image. People can see 700-900 greyscales.  Often images are too dark for people to see, so redistributing will make images more visible and useful, providing "Night vision"
        10.04 When dereferencing passed information from a callback function, make sure you are aware of what variable you are modifying
        10.05 After drawing something, use imshow immediately.  It will help debug if wrong, and make things work if right
        10.06 Did research on what to learn for future.  Conclusion is PCL, Deep Learning setup (Keras? & Tensorflow?), and yolo perhaps. Stereo vision is valuable and pose estimation
    11 August 30th, 2022: 60hr += 7  - Learned about warping images, erosion, dilation, sobel gradients, partial derivatives, gradient direction and magnitude and histograms
        11.01 A separable kernel is one where you can break it up into 2 or 3 pieces that you multiply by eachother to calculate a filter.  the computation time is the different between 2n and n^2. So one should always try to separate filters
        11.02 A sobel filter is a gradient filter that uses vertical or horizontal gradients.  It is generalizable in other ways. By calculating differences across kernels, you can find corners of images. This is like partial derivative in x and y directions
        11.03 white hat operation isolates areas that are brighter than their surroundings. Black hat finds areas darker than surroundings
        11.04 Dilation is where you take the maximum value found in a kernel and use it as the result of the convolution
        11.05 Erosion is where you use the minimum value of a convolution and use it as the result
        11.06 Opening and closing operations are combinations of the above two operations in different orders
        11.07 There are multiple smoothing functions that all have similar results and perform in similar ways:
            01. blur() is just an averaging over the kernel
            02. medianBlur() is taking the median value over the kernel during convolution.  Good for noisy images
            03. gaussianBlur() is a weighted kernel according to sigma values in x and y directions with different weights for each pixel in the kernel.  The anchor has highest weight value
            04. bilateralFilter is different from gaussian and useful for image segmenting because although it is a weighted filter, it weights pixels in the kernel depending on their intensity similarity to the anchor's intensity. This preserves edges by encouraging only the uniform sections to smooth eachother out and not mix with other intensity sections
        11.08 Depth of output is the variable value (CV_8U, CV_16U, etc...)
        11.09 In opencv, a kernel is called a structuring element. To make my own kernel I can use cv::getStructuringElement()
        11.10 Use cv::filter2D() to filter using your own kernels.  OpenCV is optimized for this, DON'T DO IT MANUALLY
        11.11 Histograms are useful for categorizing data from images. This statistical interpretation can be useful for image identification. Histograms can function in multiple dimensions. Need more learning here
        11.12 You can warp an image by using warp matricies. This is like in mechanical engineering where we would rotate coordinate frames by multiplying by the correct rotation matrix.  This can be done by multiplying over an entire matrix to scale, rotate, skew and perform many other operations
        11.13 Histograms should be normalized in order to work with their data.  It makes it all easier. 
        11.14 Arrow keys have no assigned ascii values and are simply interpretted by a program in windows.  This explained why online video games always use WASD
        11.15 cv::warpAffine() can do the warping with simple 2x2 matrices.  But to do more complex "perspective" warping, one needs a 3x3 matrix
    12 September 19th 2022: 67hr += 4 - Reviewed dilation, erosion, opening, and closing, along with other image operations. Completed exercises 1-4 of Chapter 10
        12.01 Resize does not add padding to the boundaries of the images, it actually resizes everything inside
        12.02 Abs diff subtracting two barely shifted images creates an outline of every object/major boundary in the image. Incredibly interesting
        12.03 Subtracting two images shows difference between two images. I've begun making a "difference finding program" that will spot the differences in two images and circle them. This encompassed most of the day's work.
        12.04 Shifting two slightly skewed images to realign them is not super easy, it requires summing of the entire image and checking minimums
            12.04.01 Operation is similar to convolution. Could you use a convolution to complete? What about a convolution between two images?
        12.05 Morphological gradients use dilation and erosion to clean up images and then highlight an objects outline. This is good because it does it over the whole image and on parts a sobel filter might miss.
    13 September 20th 2022: 71hr += 8 - Continued work on the spot the difference program. Could improve it by adding ROI box to main differences. Learned Viola-Jones face detect algorithm concepts
        13.01 It is extremely important that you format whatever data you get when you first start a program. Once the data is formatted, issues won't cascade.
        13.02 You can pad an image by making a larger one and copying the data from the original into it. This allows you to shift the second image around ontop of the first one for alignment
        13.03 Resizing an image is a possible way to evaluate results over a large image. It provides noisy feedback but has some merit
        13.04 Another great way to get feedback is to evaluate what you want on a small part of the image, and once you get your result, apply your steps to the entire image only once
        13.05 Calculating integral images is a way to take an N^2 operation and make it 0(N). Integral images are used for summing/scanning large images for their features. Need to Practice more
        13.06 It is incredibly useful to visualize each step along the way to your result. Do small checks of each image processing steps along the way using imshow and waitKey(0). Much better than std::cout
        13.07 Thresholding is a great way to remove noise from a system. the closing() process isn't as good for cleaning up if the difference between noise and signal isn't strong
        13.08 Using a small mat variable of a large image is a great way to examine small portions of an image for calculation, and it provides it's own padding along the edges
        13.09 Use constants more often!
        13.10 Using the function morphologicalEx() I can access the blackhat, whitehat, opening, and closing methods, and more. Opening seems to clean up the image better than doing the individual operations themselves.
        13.11 Opening method appears to be really good at identifying whole objects with color changes, but small lines will be lost in the process.
    14 October 3rd, 2022: 79hr += 8 - 
        14.01 Smoothing functions don't have masks naturally, but you can make your own mask by separating the masked region into its own image, then blurring that portion, then masked addition/assignment back into the original photo, and it will achieve the same effect
        14.02 Flood fill function is great for comparing connected regions of a mask or even natively in an image. It will retrieve area for you and you can use it to remove "noise" objects from an image. Or to filter for certain size objects. VERY useful
        14.03 HSV representation is good for picking out blue regions of a picture, or any specific color region you are looking for. Threshold functions are important for masks
        14.04 Can use bitwise functions with masks to expand or filter their regions. I used it for combining a saturation strength filter with the blue hue to find regions that were more blue than other regions 
        14.05 Top hat function has some usefulness in finding corners of a room, but only if lighting gradients are strong.  Still need to learn pointcloud for better sensing
        14.06 Super important to order the row and col settings right, it easily breaks a program, and opencv isn't consistent
        14.07 It might be possible to create adaptive filters for specific color types
        14.08 Imshow does not accept HSV images, they must be converted back to orignal BGR
        14.09 Almost done with chapter 10 exercises and lessons. There are 18 exercises!
    15 October 4th, 2022: 87hr += 6 - 
        15.01 There is something wrong about the add function where if you try to add a mask and unmasked image together
        15.02 Canny edge detection is probably best for detecting solid edges, but, Laplacian is very strong too, and finds edges while bringing in speckled noise that can be filtered with special methods
        15.03 Image and mask naming is super important for readability of code.  Structured and labelled steps in the programming process are also super important
        15.04 Using the two different partial derivatives of the sobel filter might be good, and then combining them together for edge detection, but it needs some work.
        15.05 Set to function has a masking feature, which is incredibly useful img.setTo(0, mask) makes everything in the mask 0!
        15.06 Fewer hard set lessons learned yesterday, but more general learning about how to code, structure, what algorithms to use, and how to make good outputs
        15.07 Developed my own first use for typedef keyword by creating a scanning snippet that goes through an image pixel by pixel, using the PIXEL as the special type which could be any size depending on the image!
    16 October 5th, 2022: 93hr += 6 - Day of going back to the basics and practicing inheritance, classes, header & implementation files, vectors, maps, and ENUMs. No changes within OpenCV. 
        16.01 Practiced classes and inheritance along with structs and default constructors
        16.02 Vector, map, and ENUM practice, brushing up on skills
        16.03 Reminder of header files and implementation files setup. 
        16.04 Learning lessons of how to work with math and remind myself to think about edge cases and how they clash with normal use cases.
    17 October 6th, 2022: 99hr +=  6 - Getting back to OpenCV! Hitting the 100hr mark! TIL pyrMeanShiftSegmentation and how segmentation works within feature-spaces in general
        17.01 Learned pyrMeanShiftSegmentation and how they use feature space density functions to segment colors. 
            The issue with this is if you pick too broad of a density function, or too narrow, you cannot converge on a maxima or mode
            The parameters of this function are very sensitive. The pyr feature decides how much the image is shrunk before calculation
        17.02 Feature spaces are useful for classification of objects and can be used with infinite numbers of features.  I believe they are used in machine learning
        17.03 I learned how to make my own kernel, you can do this with the command:
            cv::Mat1f k = (cv::Mat1f(5,5)<< 0,0,0,0,0,0... ) where you input all the kernel weights
        17.04 Kernels are best created by using zero sum kernel weights in order for the pictures to not become too bright.
        17.05 Often, if the weights are less than 0 total, the image will be black after filtering
        17.06 Use filter2D() in order to input your own kernel and filter an image
        17.07 To make a 45 degree line filter, you often have to put the weights in the kernel orthogonal to the line direction that you want, so that the filter will find big differences along the edges.
    18 October 7th 2022: 105hr += 5 Today I learned about the Laplacian operator and how it can kinda be used to pick out eyes in image
        18.01 The laplacian operator can be used to pick out eyes (sorta) in images. The book says it prefers a bright region in center and dark areas around, HOWEVER, after interpretting the laplacian filter myself, it appears to like dark centers and bright surroundings
        18.02 I can adjust the laplacian kernel size and it changes detection. Big kernel == big lines at edjes. Small kernel = small edge details.  The closing operation may prove useful in removing noise for laplacian
        18.03 Should consider pyrDown the image before applying laplacian in order to find pupils.  But need some way of scaling back up and translating small image coordinates to large image
        18.04 Maybe I can make my own laplacian kernel that is bigger and spread out to make it work on larger images?
        18.05 Histogram equalization is how you take an image that was captured with poor sensor range, and you spread out the inputs to the full range of the display resource, allowing the image to look better, and compensate for poor capture quality (darks are darker, whites are whiter)
            18.05.01 - equalizeHist() does this quite well
        18.06 Chapter covers resize(), but also affine and perspective transfomations. Affine transformations are simple and often maintain the image's integrity by only warping it in parallelogram ways
        18.07 Chapter also covered inpainting, but no exercises completed yet.
    19 October 11th, 2022: 110hr += 
        19.01 
    

        
